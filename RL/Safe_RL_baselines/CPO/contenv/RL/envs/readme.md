
Here we put the environments on which our safe control algorithm is applicable, and corresponding description pdfs. The environments are written so as to return a suitable reward and cost function after the env.step() function similar to Gym environments. This allows us to use them for training safe RL algorithms.
